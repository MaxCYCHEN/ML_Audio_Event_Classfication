{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9add0787-4608-4fb7-97db-740e4fd6807e",
   "metadata": {},
   "source": [
    "# Convert the test audio data to C source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "faec2c78-9261-41c3-a8ed-79668d4c7c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interact_manual\n",
    "from IPython.display import Image, clear_output\n",
    "from pydub import AudioSegment\n",
    "import os\n",
    "\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.io.wavfile import read, write\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "327d2ff1-e5a3-4505-80b8-7b1c970bb3ef",
   "metadata": {},
   "source": [
    "## Export the audio file to header file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "752704de-74ea-4c22-b91f-bfbb68efc6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class audioFileP:  #father class\n",
    "    def __init__(self, folder, filename, output):\n",
    "        self.folder = folder\n",
    "        self.filename = filename\n",
    "        self.filepath = folder + '\\\\' + filename\n",
    "        self.out = output\n",
    "        #self.rate, self.data = read(self.filepath)\n",
    "        self.data, self.rate = librosa.load(self.filepath, sr=16000, duration=10)\n",
    "        self.data = self.data[24000:57408] # Choose the range you want\n",
    "    \n",
    "        print(\"Sample rate: {} Hz\".format(self.rate))\n",
    "        print(\"Data type: {}\".format(self.data.dtype))\n",
    "        print(len(self.data))\n",
    "         \n",
    "    def create_tag_folder(self, tag_name):\n",
    "        dir_path = os.path.join(os.getcwd(), tag_name)\n",
    "        try:\n",
    "            os.mkdir(dir_path)\n",
    "        except OSError as error:\n",
    "            print(error)\n",
    "            print('skip create')\n",
    "            \n",
    "        print(os.getcwd())\n",
    "    def main(self):\n",
    "        with open(self.out, 'w') as f:\n",
    "            f.write(\"#define WAVE_DATA {\")\n",
    "            self._write_tflite_data(f, self.out)\n",
    "        \n",
    "    \n",
    "    def _write_tflite_data(self, open_file, out_path):\n",
    "        \n",
    "        line=''\n",
    "        i = 1;\n",
    "        for i, v in enumerate(self.data):\n",
    "            line = line + str(v) + ','\n",
    "        line = line + '}\\n'\n",
    "        open_file.write(line)\n",
    "           #try:\n",
    "           #    line = line + str(v) + ','\n",
    "           #    if i % 20 == 0:\n",
    "           #        line = line + '\\n\\t'\n",
    "           #        open_file.write(line)\n",
    "           #        line = '' \n",
    "           #    i += 1\n",
    "           #except StopIteration:\n",
    "           #    ine = line[:-2] + '};\\n'\n",
    "           #    open_file.write(line)\n",
    "           #    break\n",
    "        \n",
    "        #C:\\Users\\ML_m460bsp_tflu\\SampleCode\\tflu_kws_arm\\raw\n",
    "        #raw/left_2.h\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db6bc292-2a4d-4683-8964-469155d00537",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_folder = r\"datasets\\ESC-50\\audio\"\n",
    "src_file = r\"1-100032-A-0.wav\"\n",
    "dst_file = r\"outputs\\2024_02_05_16_28_26\\C_header\\1-100032-A-0-dog_1.5_3.5.h\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f6b0c69-564b-4733-9d37-baaeee828c3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample rate: 16000 Hz\n",
      "Data type: float32\n",
      "33408\n"
     ]
    }
   ],
   "source": [
    "x = audioFileP(src_folder, src_file, dst_file)\n",
    "x.main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f7f3b3-478b-4b21-b8bb-adc5f8536514",
   "metadata": {},
   "source": [
    "# Convert tflite to C source file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33a8bfa4-1adc-420c-a7ba-ed91d6062514",
   "metadata": {},
   "outputs": [],
   "source": [
    "tflite_name = r\"outputs\\2024_02_05_16_28_26\\quantized_models\\quantized_model.tflite\"\n",
    "out_file = r\"outputs\\2024_02_05_16_28_26\\C_header\\quantized_miniresnetv2.c\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5c030cf-d447-489a-9806-4aa1f25bb2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "! python tflite_to_tflu.py --tflite_path $tflite_name --output_path $out_file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ecc348-ef65-41f2-b147-570d4078cd15",
   "metadata": {},
   "source": [
    "# Test the preprocess values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "342911e3-5268-4554-a5d7-fa582ce2757a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys,os,logging\n",
    "sys.path.append(os.path.abspath('../utils'))\n",
    "from preprocess import load_and_reformat\n",
    "from feature_extraction import get_patches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1acad59-aa55-45f8-961b-a936f81f2907",
   "metadata": {},
   "source": [
    "## A. The training preprocess + feature Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d37bb52b-27d6-44bc-85ae-f87532d768f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_folder = r\"datasets\\ESC-50\\audio\"\n",
    "src_file = os.path.join(src_folder, r\"1-100032-A-0.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b41ab633-7d75-4c9b-8fd8-254cfb4dcdec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Sound wave shorter than min_length, repeating\n",
      "[INFO] Sound wave repeated 3 times\n",
      "db_melspec\n",
      "101 64\n"
     ]
    }
   ],
   "source": [
    "wave, sr = load_and_reformat(wave_path=src_file,\n",
    "                                 min_length=2,\n",
    "                                 max_length=10,\n",
    "                                 target_rate=16000,\n",
    "                                 top_db=60,\n",
    "                                 frame_length=3200,\n",
    "                                 hop_length=3200,\n",
    "                                 trim_last_second=False)\n",
    "        \n",
    "patches = get_patches(wave=wave,\n",
    "                      sr=sr,\n",
    "                      patch_length=50,\n",
    "                      overlap=0.25,\n",
    "                      n_fft=1024,\n",
    "                      hop_length=320,\n",
    "                      include_last_patch=False,\n",
    "                      win_length=1024,\n",
    "                      window='hann',\n",
    "                      center=True,\n",
    "                      pad_mode='constant',\n",
    "                      power=2.0,\n",
    "                      n_mels=64,\n",
    "                      fmin=20,\n",
    "                      fmax=7500,\n",
    "                      power_to_db_ref=np.max,\n",
    "                      norm='slaney',\n",
    "                      htk=False,\n",
    "                      to_db=True,\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "76d9c31c-e5e2-4471-8797-1b6da798696c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32000\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "print(len(wave))\n",
    "print(len(patches[1][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb07901-f9d8-43ef-9695-d89f326bc4d3",
   "metadata": {},
   "source": [
    "## B. The Inference Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f69b6743-508b-4fea-8739-8be8e68f6885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "db_melspec\n",
      "251 64\n",
      "[[-41.457413 -35.091324 -37.754646 ... -80.       -80.       -80.      ]\n",
      " [-47.76841  -42.010834 -44.58092  ... -80.       -80.       -80.      ]\n",
      " [-42.961098 -36.48146  -45.14736  ... -80.       -80.       -80.      ]\n",
      " ...\n",
      " [-77.72628  -67.10232  -55.49411  ... -80.       -80.       -80.      ]\n",
      " [-80.       -72.94021  -57.0795   ... -80.       -80.       -80.      ]\n",
      " [-80.       -74.87651  -66.781906 ... -80.       -80.       -80.      ]]\n"
     ]
    }
   ],
   "source": [
    "src_folder = r\"datasets\\ESC-50\\audio\"\n",
    "src_file = os.path.join(src_folder, r\"1-110389-A-0.wav\")\n",
    "\n",
    "wave, sr = librosa.load(src_file, sr=16000, duration=10)\n",
    "\n",
    "#wave = wave[24000:57408] #wave[24000:40704] #wave[24000:57408]\n",
    "\n",
    "patches = get_patches(wave=wave,\n",
    "                      sr=sr,\n",
    "                      patch_length=50,\n",
    "                      overlap=0.25,\n",
    "                      n_fft=1024,\n",
    "                      hop_length=320,\n",
    "                      include_last_patch=False,\n",
    "                      win_length=1024,\n",
    "                      window='hann',\n",
    "                      center=True,\n",
    "                      pad_mode='constant',\n",
    "                      power=2.0,\n",
    "                      n_mels=64,\n",
    "                      fmin=20,\n",
    "                      fmax=7500,\n",
    "                      power_to_db_ref=np.max,\n",
    "                      norm='slaney',\n",
    "                      htk=False,\n",
    "                      to_db=True,\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "fe42b164-81c6-406e-bef7-bf1bac1643a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total wav time: 80000\n",
      "Num patches: 6\n",
      "64\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "print(\"Total wav time: {}\".format(len(wave)))\n",
    "print(\"Num patches: {}\".format(len(patches)))\n",
    "print(len(patches[0]))\n",
    "print(len(patches[0][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a917a0a3-29a0-4178-b728-f6030c55e453",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn.metrics\n",
    "import tensorflow as tf\n",
    "import tqdm\n",
    "from hydra.core.hydra_config import HydraConfig\n",
    "from evaluation import _aggregate_predictions, compute_accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d445f91c-bfc4-4e9f-8cbe-0f0c8182a5a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Roaming\\Python\\Python38\\site-packages\\numpy\\core\\numeric.py:2468: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  return bool(asarray(a1 == a2).all())\n"
     ]
    }
   ],
   "source": [
    "clip_labels = []\n",
    "clip_labels.extend([0] * len(patches)) # only 1 test data\n",
    "clip_labels = np.array(clip_labels)\n",
    "\n",
    "X = []\n",
    "y= []\n",
    "\n",
    "X.extend(patches)\n",
    "X = np.stack(X, axis=0)\n",
    "X = np.expand_dims(X, axis=-1)\n",
    "\n",
    "y.extend(['dog'] * len(patches))\n",
    "vocab = ['dog', 'chainsaw', 'crackling_fire', 'helicopter', 'rain',\n",
    "       'crying_baby', 'clock_tick', 'sneezing', 'rooster', 'sea_waves']\n",
    "string_lookup_layer = tf.keras.layers.StringLookup(\n",
    "        vocabulary=sorted(list(vocab)),\n",
    "        num_oov_indices=0,\n",
    "        output_mode='one_hot')\n",
    "y = np.array(string_lookup_layer(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8d8e1ebb-b5d9-4fd5-8c83-e665ddaea7e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 64, 50, 1)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(type(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ca2a6adf-bc7d-4bfd-bc50-1b4488b27219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Evaluating the quantized model ...\n",
      "[INFO] Quantization input details : (0.3137255012989044, 127)\n",
      "[INFO] Dtype input details : <class 'numpy.int8'>\n",
      "-128 127\n",
      "[INFO] : Quantized model patch-level accuracy on test set : 0.16666666666666666\n"
     ]
    }
   ],
   "source": [
    "#tflite_name = r\"outputs\\2024_02_05_16_28_26\\quantized_models\\quantized_model_audio.tflite\"\n",
    "#tflite_name = r\"C:\\Users\\USER\\Desktop\\ML\\tiny_nu_audio\\workspace\\2024_03_13_16_13_45_512hop_woOther\\quantized_models\\quantized_model.tflite\"\n",
    "tflite_name = r\"C:\\Users\\USER\\Desktop\\ML\\ML_tf2_image_classfication_nu\\vela\\generated\\quantized_miniresnetv2.tflite\"\n",
    "\n",
    "X_test = X\n",
    "y_test = y\n",
    "\n",
    "tf.print('[INFO] Evaluating the quantized model ...')\n",
    "interpreter_quant = tf.lite.Interpreter(model_path=tflite_name)\n",
    "\n",
    "input_details = interpreter_quant.get_input_details()[0]\n",
    "#print(input_details)\n",
    "output_details = interpreter_quant.get_output_details()[0]\n",
    "#print(output_details)\n",
    "\n",
    "tf.print(\"[INFO] Quantization input details : {}\".format(input_details[\"quantization\"]))\n",
    "tf.print(\"[INFO] Dtype input details : {}\".format(input_details[\"dtype\"]))\n",
    "input_index_quant = interpreter_quant.get_input_details()[0][\"index\"]\n",
    "\n",
    "output_index_quant = interpreter_quant.get_output_details()[0][\"index\"]\n",
    "interpreter_quant.resize_tensor_input(input_index_quant, list(X_test.shape))\n",
    "interpreter_quant.allocate_tensors()\n",
    "X_processed = (X_test / input_details['quantization'][0]) + input_details['quantization'][1]\n",
    "\n",
    "print(np.iinfo(input_details['dtype']).min, np.iinfo(input_details['dtype']).max)\n",
    "#print(np.round(X_processed))\n",
    "\n",
    "X_processed = np.clip(np.round(X_processed), np.iinfo(input_details['dtype']).min, np.iinfo(input_details['dtype']).max)\n",
    "X_processed = X_processed.astype(input_details['dtype'])\n",
    "#print(X_processed)\n",
    "\n",
    "interpreter_quant.set_tensor(input_index_quant, X_processed)\n",
    "interpreter_quant.invoke()\n",
    "preds = interpreter_quant.get_tensor(output_index_quant)\n",
    "\n",
    "# Aggregate predictions\n",
    "aggregated_preds = _aggregate_predictions(preds=preds,\n",
    "                                            clip_labels=clip_labels,\n",
    "                                            is_multilabel=False,\n",
    "                                            is_truth=False)\n",
    "aggregated_truth = _aggregate_predictions(preds=y_test,\n",
    "                                            clip_labels=clip_labels,\n",
    "                                            is_multilabel=False,\n",
    "                                            is_truth=True)\n",
    " #generate the confusion matrix for the float model\n",
    "patch_level_accuracy = compute_accuracy_score(y_test, preds,\n",
    "                                                is_multilabel=False)\n",
    "print(\"[INFO] : Quantized model patch-level accuracy on test set : {}\".format(patch_level_accuracy))\n",
    "\n",
    "#clip_level_accuracy = compute_accuracy_score(aggregated_truth, aggregated_preds,\n",
    "#                                                is_multilabel=False)\n",
    "#print(\"[INFO] : Quantized model clip-level accuracy on test set : {}\".format(clip_level_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "307b2748-adfa-4cbb-a4da-fa25a2fdbacb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-128 -120 -128 -128  103 -128 -128 -125 -128 -114]\n",
      " [-128 -127 -128 -128 -125 -128 -128  -47 -128   42]\n",
      " [-128 -127 -128 -128 -125 -128 -128  -47 -128   42]\n",
      " [-128 -127 -128 -128 -125 -128 -128  -47 -128   42]\n",
      " [-128 -127 -128 -128 -125 -128 -128  -47 -128   42]\n",
      " [-128 -127 -128 -128 -125 -128 -128  -47 -128   42]]\n"
     ]
    }
   ],
   "source": [
    "print(preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "cabcb39a-c013-42d2-8a1b-e088c96f0bc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00390625\n",
      "-128\n"
     ]
    }
   ],
   "source": [
    "print(output_details['quantization'][0])\n",
    "print(output_details['quantization'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "40a85c60-ab82-4841-92c0-4a01dd83b150",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.03125    0.         0.         0.90234375 0.\n",
      "  0.         0.01171875 0.         0.0546875 ]\n",
      " [0.         0.00390625 0.         0.         0.01171875 0.\n",
      "  0.         0.31640625 0.         0.6640625 ]\n",
      " [0.         0.00390625 0.         0.         0.01171875 0.\n",
      "  0.         0.31640625 0.         0.6640625 ]\n",
      " [0.         0.00390625 0.         0.         0.01171875 0.\n",
      "  0.         0.31640625 0.         0.6640625 ]\n",
      " [0.         0.00390625 0.         0.         0.01171875 0.\n",
      "  0.         0.31640625 0.         0.6640625 ]\n",
      " [0.         0.00390625 0.         0.         0.01171875 0.\n",
      "  0.         0.31640625 0.         0.6640625 ]]\n"
     ]
    }
   ],
   "source": [
    "preds = preds.astype('float')\n",
    "preds_q = (preds - output_details['quantization'][1]) * output_details['quantization'][0]\n",
    "print(preds_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9fc17c-218f-4832-90f6-8d16ee3bf81e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
